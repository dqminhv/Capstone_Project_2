{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPfKwdAlTOUDpoGZhSeB12+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dqminhv/fraudulent-job-posting-detection-with-NLP/blob/main/notebook/modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "57ISXwfSJ-kD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree, metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the imbalanced nature of the dataset and the task of classifying fraudulent job postings based on job descriptions, several classification algorithms can be considered. However, algorithms that handle class imbalance well and are robust to noisy data are typically preferred. Here are some algorithms that you may want to consider:\n",
        "\n",
        "- **Random Forest**: Random Forest is an ensemble learning algorithm that works well with imbalanced datasets. It builds multiple decision trees and combines their predictions to improve accuracy.\n",
        "\n",
        "- **Gradient Boosting Machines (GBM)**: GBM algorithms like XGBoost, LightGBM, and CatBoost are also effective for imbalanced classification tasks. They sequentially build multiple weak learners to minimize a loss function, which often leads to better performance on imbalanced datasets.\n",
        "\n",
        "- **Support Vector Machines (SVM)**: SVM is a powerful algorithm for binary classification tasks. By adjusting the hyperparameters, such as the regularization parameter (C) and the kernel function, SVM can be effective for imbalanced data.\n",
        "\n",
        "- **Logistic Regression**: Despite its simplicity, logistic regression can perform well on imbalanced datasets, especially when combined with techniques like class weighting or penalization.\n",
        "\n",
        "- **AdaBoost**: AdaBoost is an ensemble learning algorithm that combines multiple weak classifiers to create a strong classifier. It is known to perform well on imbalanced datasets.\n",
        "\n",
        "- **Neural Networks**: Deep learning models, such as neural networks, can also be effective for imbalanced classification tasks, especially when dealing with large datasets. Architectures like Convolutional Neural Networks (CNNs) or Recurrent Neural Networks (RNNs) can capture complex patterns in text data.\n",
        "\n",
        "- **Naive Bayes**: Despite its simplicity and assumption of feature independence, Naive Bayes can perform surprisingly well on text classification tasks, including imbalanced datasets."
      ],
      "metadata": {
        "id": "uKBxb04tYwfD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load train/test data"
      ],
      "metadata": {
        "id": "Ly0FYhvCZwu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.read_csv('https://raw.githubusercontent.com/dqminhv/fraudulent-job-posting-detection-with-NLP/main/Data/X_train.csv')\n",
        "X_test = pd.read_csv('https://raw.githubusercontent.com/dqminhv/fraudulent-job-posting-detection-with-NLP/main/Data/X_test.csv')\n",
        "y_train = pd.read_csv('https://raw.githubusercontent.com/dqminhv/fraudulent-job-posting-detection-with-NLP/main/Data/y_train.csv')\n",
        "y_test = pd.read_csv('https://raw.githubusercontent.com/dqminhv/fraudulent-job-posting-detection-with-NLP/main/Data/y_test.csv')"
      ],
      "metadata": {
        "id": "fUbOm9KHacO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorizing text data"
      ],
      "metadata": {
        "id": "kmlHbqpoZz5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters\n",
        "stop_words = 'english'\n",
        "min_df = .2\n",
        "max_df = .7\n",
        "ngram_range=(1, 1)"
      ],
      "metadata": {
        "id": "RkO-CLauZ71W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using TfidfVectorizer\n",
        "tfidf_vect = TfidfVectorizer(stop_words=stop_words, max_df=max_df, min_df=min_df, ngram_range=ngram_range)"
      ],
      "metadata": {
        "id": "we-qtxf0aCH1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}